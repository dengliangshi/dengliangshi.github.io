---
layout: post
title: Some Ideas about Further Research on Neural Network Language Models
abstract: In this post, the limits of existing neural network language models are analysed, and some possible directions of further searches on neural network language models are proposed.
---

### 1. Introduction
but none of these works the nature of neural network language models.

### 2. Limits of NNLMs


#### 2.1 Knowledge Representation
Knowledge learned by NNLMs from data set is the probabilistic distribution of a language, strictly speaking, is the probabilistic distribution of the usage
of a language in the database, rather than the knowledge of the language, like grammer, and ect. or the knowledge represented by the language. NNLMs may show excellent performance in some special application like speech recognization, machine translation and so on, but they cannot understand the information conveyed by the language.

Knowledge, abstract or concrete, 

without any connections to the real world, NNLMs never be capable of understanding a language.

#### 2.2 Architecture
Learned knowledge is saved as weight matrix,

features detection and knowledge representation using different neural network

variety of structures to enhance the ability to detect features of nerual network, and decrease the difficulty to training.

### 3. Further Research
Artificial neural network models imitate biological neural system, but the functions, like feature detection, information and knowledge representation, are implemented by different parts of biological neural network, artifical neural network mix these function together.

Take the visual neural system of human as an example, 

determine a word sentence is correct or not by the frequency of word sentences
Althogh the improved nerual probabilistic language model show excellent perform, there still are some .

The performance of neural probabilistic language models are overstate. Artificial neural networks are a kind of function approximation method, and 

If feature detection and knowlege representation can be achieved by different parts of neural network model or by neural network models with different architectures, 

### 4. Conclusion
?

### References